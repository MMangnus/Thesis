\section{Introduction}
%Positive intro to set the stage)
The field of neuroimaging is rapidly adopting a more reproducible approach to data acquisition and analysis. Especially in recent years, a strong movement for conducting better documented and more reproducible science can be observed. Advances have been made in terms of openly sharing data (e.g. OpenFmri, \cite{Poldrack2013}), standardizing data formats (BIDS format \cite{Gorgolewski2016}), and facilitating more automated pipelines \cite{Fischl2004,Gorgolewski2011,Jenkinson2012}. These initiatives facilitate increasing global scientific communication and collaboration, that is paramount in the age of big data.

%Problem: software limitations
As a result of the increasing complexity of analyses\remove{, however,} and the wide variety of different tools, researchers often have to write custom scripts for combining different software packages, often in different programming languages. As an extra obstacle, many tools have external dependencies, intricate installation procedures, or different file formats for the same type of data. Furthermore, the sharing initiatives usually have a stronger focus on sharing \emph{data} (Human Connectome Project \cite{Elam2015}, NeuroVault \cite{Gorgolewski2015}) instead of \emph{code}, such that analysis scripts still have to be recreated based on the method section of a paper. All these factors negatively affect the reproducibility, documentation, and in the worst case correctness of the analysis \cite{Nosek2015}.
%and may be seen as a waste of money by the greater public, as most research is funded by the tax payer. 

%Problem: people limitations
A considerable mastery of coding is required for analysing fMRI data. The conceptual side of understanding all preprocessing steps is not trivial, but converting this into a working pipeline can be an arduous journey. The necessary programming skills are not usually the prime focus of a brain researcher's skills or interests, but they are a necessity for completing one's analysis. Consequently, scripting a pipeline that covers all high-level and low-level aspects is daunting and error prone. As a result, there is a considerable risk \change{one will revert to}{of} `hacking' an analysis pipeline together, sacrificing a reproducible approach. So as a researcher, how do you start an analysis? It is easiest to start with visualising the steps of your analysis pipeline.  

%Current solutions and shortcomings
In an increasingly complicated analysis environment there is a strong need for tools that give a better oversight of these complex analyses, while retaining the flexibility of combining different tools. A notable effort to integrate different tools is Nipype \cite{Gorgolewski2011}, that has a Python interface to existing tools from all major MRI analysis packages. However, this still requires non-trivial Python scripting. Furthermore, Nipype is only able to visualise a workflow after it has been manually scripted \cite{Ellson2002}.

%Our solution
Here we detail our solution to these problems, an open-source software program we call Porcupine: 'PORcupine Creates Ur PipelINE\remove[Reviewer 2]{- the worst recursive acronym with bad capitalisation and annoying use of slang'}. Porcupine allows the creation of neuroimaging pipelines by means of a graphical user interface (GUI). After graphical pipeline definition, Porcupine in turn creates the code that programmatically defines the pipeline. Additionally and without any additional overhead, we supply a Dockerfile (\url{https://www.docker.com}) that automatically builds the run environment for the pipeline. This not only facilitates sharing the pipeline, but also ensures its reproducibility \cite{Boettiger2015}. We provide an extensive list of examples and documentation on our \href{https://timvanmourik.github.io/Porcupine/examples}{website}, as well as the possibility to upload one's custom pipeline to create a community driven library of analyses.

%Details about solution
By implementing an intermediate visual step in the generation of preprocessing workflows, Porcupine allows the user to focus on the logical flow of the preprocessing pipeline in a graphical representation without the need for coding at this conceptual stage of development. Because the GUI produces \change[Reviewer 2]{working}{functional} analysis code, the user can\remove[Reviewer 2]{then} immediately inspect, save, and run the generated code. Thus, Porcupine provides a stepping stone that eases the transition from concept to implementation. Because the entire pipeline and its parameters are defined \emph{in abstracto} before it is run, systems such as Nipype allow for elaborate checks and optimisations of the pipeline's execution. Furthermore, such systems can straightforwardly incorporate full logging of all analysis steps, creating a paper trail of the pipeline's execution. This combination of a reproducible environment in which a predefined pipeline is run by means of a system that provides precise bookkeeping paves the way to new standard that will ensure steady and reproducible progress in the field of cognitive neuroimaging \cite{Gorgolewski2016a}. 

%Concluding remarks
In our practical experience, the use of Porcupine allows one to very quickly prototype preprocessing pipelines. Novice users can create a pipeline \emph{de novo} and quickly focus on the code for this pipeline, greatly speeding up the learning process and thereby facilitating the use of reproducible pipelines. We envisage Porcupine to play a role in both the education of novice neuroimaging students and the rapid prototyping of pipelines by expert users. Here, we first outline several Porcupine use-case scenarios of increasing complexity, after which we detail the architecture of Porcupine.


