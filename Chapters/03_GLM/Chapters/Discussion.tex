\section{Discussion and Conclusions}
% Conclusion
In this study, we propose a new method to reduce the inherent blurring of laminar profiles of current methods. Instead of interpolating a volume and averaging over a region of interest, we propose to unmix the laminar signals by using a spatial General Linear Model (GLM). In order to further reduce partial volume contamination we propose using the orientation of the voxel with respect to the cortex to better model the layer contributions to each voxel. While this provides an additional type of prior knowledge to incorporate into the layer estimation, the improvements on the layer estimates are marginal. We compute a spatial Point Spread Function (PSF) of existing cortical signal extraction methods on simulated data and explore the benefits and caveats of the spatial GLM when it is performed on human structural MRI data. On simulated data, we show that the GLM clearly outperforms existing methods, especially on a coarser resolution. However, it may be more sensitive to the imperfections of real human MRI data and result in artifacts in the extracted profile, mainly when a high number of layers is used. An initial version of this method has been applied to functional data by Kok et al. \cite{Kok2016} and in \change{Chapter 4 of this thesis}{Van Mourik et al (2018, in prep)} \cite{VanMourik2018a}.

% Assumptions of the GLM
The framework of the GLM is a well described mathematical tool and many principles transfer directly to our proposed spatial application. The core assumption of the GLM (as well as \change{for}{of} existing methods) is that the laminar signals across every layer within the ROI are assumed to be constant. This means that any bias field that stretches through the region of interest may be detrimental to the results. Another important assumption is the normality of errors, either uncorrelated in an ordinary least squares estimation, but potentially correlated for a generalised least squares estimation. This normality is not guaranteed (and sometimes not even expected) in a laminar GLM, due to the many different sources of noise. Apart from thermal noise in the data, important sources can be the presence of e.g. blood vessels that systematically bias some part of the region of interest.
%
At least as important as noise in the data, is noise in the model. Whenever the layer specific design matrix does not match the true underlying structure, (systematic) errors are likely to appear. While the assumed equivolume model for the cortex is the best description to date, it cannot be assumed to be a flawless description of the true cortical layering. \add{Additionally, algorithmic implementations by necessity make numerical approximations that may induce noise as well.} \change{Additionally,}{Correct layering also depends on the quality of the} cortical reconstructions \add{that} may contain errors, especially in regions where the cortex is thin \change{(i.e. visual cortex)}{(i.e. primary visual or somatosensory cortex), highly myelinated (i.e. primary areas),} or regions of reduced signal (e.g. temporal lobe, but highly dependent on acquisition). Related to this, there is a high co-occurence of neighbouring layers in the same voxels, which directly translates into a high covariance between neighbouring layer regressors. In general, covariance between regressors may induce anticorrelations, closely related to the well known anticorrelations found after global signal regression \cite{Uddin2009}. It should therefore come as no surprise that we find the point spread function of the GLM to have sinc-like characteristics and that profiles with many layers (i.e. more heavily correlated regressors) show oscillating patterns.

% Balancedness of design
\change{In the same way that it is important to have a balanced design matrix (over conditions) in a temporal GLM}{It is well known that a temporal design matrix needs to be balanced over conditions. Conditions needs to be represented equally in the model, or otherwise the estimation may be biased towards overrepresented conditions. Similarly}, it is important to have a balanced spatial design. If not, the estimation will be biased towards the overrepresented layer. This has an immediate practical implication: our implementation allows for differing layer thicknesses, which can be useful in order to match the \change{histological}{cytoarchitectonic} layer thickness. But care must be taken, as this may introduce a bias towards the thicker layers as they contribute more to the squared error.
% error bars
We do not provide error margins on our retrieved layer estimates, as the \add{number of }degrees of freedom in our data is not equal to the number of voxels. A valuable course for further research could be a more accurate estimation of the true degrees of freedom in order to get a better handle on the reliability of the extracted layer profiles. 

The main caveat of the GLM method is the potential anticorrelation that is artificially induced in neighbouring layers. This artifact presents itself in space, but also directly translates into lower temporal correlations between neighbouring layers. As a result, one may easily conclude that neighbouring layers are temporally more distinct than is justified. Additionally, this artifact is amplified when the difference between neighbouring layers is large. Unfortunately for fMRI, this is mainly at the white matter boundary and the CSF boundary, and consequently primarily affects the deepest and highest layers. A hypothetical equal activation over the cortex may thus be amplified to appear like deep and top layer activation. If an odd number of layers is chosen, effects from both sides may even amplify to push down every second layer. While an unmixing model alludes to a superresolution potential, we strongly advise against using it as such. Using more than one layer per voxel may compromise the stability of the extracted signals. \add{This is also illustrated by initial use in Renzo et al.} \cite{Huber2017}\add{where significant noise enhancement is observed compared to other methods.}

% Future work
An interesting extension of our proposed spatial GLM could be a more seemless integration with a temporal GLM, analogous to the commonly performed first and second level analysis. This spatio-temporal regression is currently performed as a two-stage approach, but could also be combined in the form of a mixture model. This is more powerful due to reduced propagation of errors \cite{Beckmann2003} and would directly yield task-specific laminar results. As we here focus on the validation of the single time point scenario, this is outside the scope of this paper. A different line of improvement could be a more bottom-up approach with a forward modelling perspective of the same problem\add{: a perspective where hypothesised laminar signals is multiplied with the layer model and compared to measured data}. We here took the top-down approach by taking an existing mathematical framework, but experienced \change{that several of the core assumptions of the GLM are not met, resulting in artifacts in the result}{artifacts in the result as a consequence of the model inversion}. Building this up in a different mathematical context may get around these violations of assumptions and provide a formulation that is closer to the problem at hand. Integrating a spatial component into a temporal layer specific hemodynamic forward model \cite{Heinzle2016} could be a interesting starting point.

Hitherto, a mathematical framework has been lacking which has made it difficult to assess certainty \change{values or degrees of freedom}{estimates} of laminar signals, which in turn has made it difficult to apply rigorous statistics. With this work, we hope to provide a contribution to such a framework in the field of laminar (f)MRI, such that it can be conducted on a more routine basis. The main use of this technique is envisioned in fMRI, where better layer extraction will allow a closer examination of layer specific BOLD in functional MRI. This may give new insights regarding feedback and feedforward connectivity of cortical areas. The spatial GLM poses improvements to dealing with the partial volume effect and prevents leakage to neighbouring layers. While there are several caveats of applying the spatial GLM on real data, we show that the performance on simulated data is far better than existing methods. We thus suggest that the price paid for a higher accuracy in ideal data is a higher susceptibility to less than ideal data.
