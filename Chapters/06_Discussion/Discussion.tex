
\chapter{Summary and Discussion}
\chaptermark{Discussion}
\label{ch:discussion}

For long the nature of the processing undertaken by the cortical layers has been recognised as a mystery that needs to be resolved to better understand the computations being performed by our brains \cite{Miller2001}. The most realistic method to date of studying this in living human subjects is with functional MRI, as it it very precise and non invasive. But many challenges in spatial and temporal resolution, resolution, interpretation, and all sorts of noise have to be overcome before this can be easily used to solve neuropsychological problems. The objective of this thesis was to pave the way for doing more routine laminar fMRI analysis. Indeed we made significant steps towards this end. 
We have developed several new methods that solve major problems in laminar analysis, we conducted a full layer specific analysis, and took explicit care to make everything along the way reproducible and reusable. %% <-- unpack

\section*{Chapter 2: Recursive Boundary Registration}
First, we addressed the problem of local distortions that are often present in Echo Planar Images (EPI). Due to inhomogeneities in the main magnetic field, spins in some areas rotate a bit faster or slower than others. Effectively, this causes small shifts of parts of the image with respect to the true position. Thus, even though the true locations of the layers are known, the distortions may easily be larger than the thickness of the layers. Without correcting this effect it is hopeless to get out any reliable layer signal. So that is what we set out to do in Chapter 2.

Geometry transformation from one volume to the other (coregistration) has been very succesful for linear transformations and is used routinely in fMRI analysis. Even on volumes with low resolution, low contrast, or few slices, it may work well \cite{Greve201}, but not for non-linear transformations. Such transformations require a high number of degrees of freedom because of the many parameters that need to be estimated. This leaves much more room for error and therefore usually only works on high contrast data sets. It is used routinely for transforming single subject anatomical space to a template space with the same contrast. However, existing techniques are not powerful enough to undistort low contrast EPI images. We therefore invented a new technique for this, Recursive Boundary Registration. By recursively applying linear transformations on diminishing spatial scales, we effectively compute a non linear registration. In order to guarantee smoothness over all transformations, it is combined with a control point lattice that regulates the transformations. Explicitly taking the geometry of the volume into account as a type of prior knowledge is a novel way to approach non linear registrations.

We tested RBR on two different types of data. First, in order to establish a gold standard, we distorted a FLASH image that is typically without distortion. Because we did this in a controlled manner, we could easily compare the performance of RBR to our ground truth and verify the quality of the registration. We thus proceeded to EPI data set of 11 subjects that had real distortions. As the true size of the distortions was unknown there cannot be an absolute quality metric for the registration. Instead, by adding different levels of noise we showed that there is a clear SNR dependance in the displacement that decreases towards the no-noise condition. Additionally, we provide an abundance of graphical evidence to illustrate the performance of RBR.

The power of the method lies in the fact that it makes explicit use of the gyrification of the brain and the specific geometry of an individual brain. It can therefore get away with little contrast and still produce an accurate registration while preserving the topology of the original. Because of the large number of parameters that needs to be estimated we built in a variety of robustness assurances. Despite the overall improved registration, it is still important to carefully inspect the quality of the registration to verify the required submillimetre accuracy. All in all, this proved to be a valuable tool for preparing Gradient Echo images for subsequent analyses and we use it in our experimental study in Chapter 4. It is now an integral part of the fMRI analysis toolbox for laminar fMRI, \url{https://github.com/TimVanMourik/OpenFmriAnalysis}.

An helpful realisation in developing this method was a more conceptual look on the problem. The problem of coregistration can be classified along two main axes: the type of image contrast can be different or the same, and the required transformation can be linear or non linear. The easiest scenario is to find a linear transformation for a volume with similar contrast. The problem becomes harder when the volume has a different contrast, as the mapping of intensity values from one volume to the next is unknown. If instead the contrast is the same but the required transformation is non linear, it is still solvable to a good approximation \cite{Collins1995}. However, when the contrast is different \emph{and} the registration should be non-linear the, the degrees of freedom of the problem increases drastically, and is not easily estimated anymore. Combine this with the low contrast-to-noise ratio of fMRI data and it is clear that this is a hopeless endeavour with standard volume-to-volume registration. The trick to solve this conundrum is to introduce more prior knowledge to the equation. In this case, we chose to use the geometric information of the cortex and its many gyri and sulci to more accurately estimate a non linear cross-modal registration. This does the trick on a single subject level, but by introducing prior knowledge, we restricted the use cases. Where the previous non-linear transforms could also compute subject-to-template registration, we lost this ability by strictly enforcing equal geometry across volumes. As a general notion, algorithms can become more powerful when they are more specialised. Usually this requires a specific type of prior knowledge in the data that is quantified and optimised.

\section*{Chapter 3: Spatial GLM for laminar fMRI}
Once the geometry of our cortical surfaces is properly aligned with our functional data, there is a next problem: how can the laminar signal be extracted from the MRI volume? There are several intuitive ways. A volume could simply be interpolated at the approximate location of the layers, or classify voxels to be part of it most likely layer. However, it is clear that this inherently smears out the laminar signal to some extent. In Chapter 3 we set out to quantify this signal leakage and to present a new method to reduces it and to more cleanly separate the laminar signal.

We started out with the notion that all voxels are a mixture of a variety of layers. If this mixture could be accurately modeled it could theoretically also be inverted and solved for the layer intensity values by means of the framework of the General Linear Model (GLM). To achieve this, we first set up a mathematical framework to accurately model the layer distribution and subsequently estimate the layer signal intensity. 

Our cortex model incorporates information about the precise location, curvature and thickness of the cortex to model the 



We previously mentioned that methods can become more powerful when they use types of prior knowledge inherent to the data. We here find that this is true, but might come at the cost of a la

The prior knowledge 


Due to the many factors that could play a role in the 
The combinatoric explosion of the many dimensions

\section*{Chapter 4: Layer Specificity in Visual Attention}


"In addition, excitatory neurons may quickly redistribute input from the thalamus by means of their local axonal collaterals, 
so that cortical activity nearly instantaneously spreads over several layers and columns to mediate perception of sensory stimuli (Reyes-Puerta et al., 2015)"

publication bias 
null result


\section*{Chapter 5: Pipelines for fMRI with Porcupine}






\linespread{1.5}
\newpage